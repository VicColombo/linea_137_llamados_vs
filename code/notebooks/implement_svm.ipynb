{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler, LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(''))), 'datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datos a usar\n",
    "\n",
    "- V2 --> dataset limpio\n",
    "- V4 --> variables construidas a partir de otras + agrupacion de violencias absorbidas\n",
    "- V5 --> eliminación de las variables cn poca información\n",
    "\n",
    "\n",
    "##### Pipeline\n",
    "\n",
    "1. cargar dataset\n",
    "2. reemplazar NS/NC en convive dataset por NA\n",
    "3. separar NA de convive, serán el dataset \"no visto\"\n",
    "4. separar train-test\n",
    "5. hace modificaciones para svm en train, test, y dataset final: Apply scikit's OneHotEncoder with the handle_unknown parameter set to \"ignore\"\n",
    "\n",
    "##### Modificaiones para SVM\n",
    "\n",
    "1. pasar datetime a timestamp y escalar --> OK\n",
    "2. escalar la variable edad --> OK\n",
    "3. pasar edad a categórica (en una columna distinta) --> OK\n",
    "4. reemplazar NS/NC en convive por NA\n",
    "5. pasar todas las categóricas a dummy:\n",
    "   1. edad, momento del día y estación del año con un encoder ordinal\n",
    "   2. el resto con one hot encoder excepto convive que lo paso cuando armo el modelo\n",
    "6. borrar las categóricas para hacer más pequeño el dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 cargar datasets\n",
    "\n",
    "llamados_v2= pd.read_excel(os.path.join(dataset_dir, 'xlsx/llamados_v2.xlsx'), parse_dates=['llamado_fecha_hora'])\n",
    "llamados_v4= pd.read_excel(os.path.join(dataset_dir, 'xlsx/llamados_v4.xlsx'), parse_dates=['llamado_fecha_hora'])\n",
    "llamados_v5= pd.read_excel(os.path.join(dataset_dir, 'xlsx/llamados_v5.xlsx'), parse_dates=['llamado_fecha_hora'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "todos_datasets = [llamados_v2, llamados_v4, llamados_v5]\n",
    "datasets_45 = [llamados_v4, llamados_v5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "encoder = OrdinalEncoder()\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 reemplazar todos los NS/NC en convive por na\n",
    "for dataset in todos_datasets:\n",
    "\n",
    "    # Replace the specified values with NaN\n",
    "    dataset.loc[:, 'victima_convive_agresor'] = dataset['victima_convive_agresor'].replace({'NS/NC': pd.NA})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 separar los na de convive en nuevo dataset\n",
    "\n",
    "# Create a copy of the dataset where Column F has a value NaN\n",
    "llamados_v2_no_visto = llamados_v2[llamados_v2['victima_convive_agresor'].isna()].copy(deep=True)\n",
    "llamados_v2_train_test = llamados_v2[~llamados_v2['victima_convive_agresor'].isna()].copy(deep=True)\n",
    "\n",
    "llamados_v4_no_visto = llamados_v4[llamados_v4['victima_convive_agresor'].isna()].copy(deep=True)\n",
    "llamados_v4_train_test = llamados_v4[~llamados_v4['victima_convive_agresor'].isna()].copy(deep=True)\n",
    "\n",
    "llamados_v5_no_visto = llamados_v5[llamados_v5['victima_convive_agresor'].isna()].copy(deep=True)\n",
    "llamados_v5_train_test = llamados_v5[~llamados_v5['victima_convive_agresor'].isna()].copy(deep=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "llamados_v2_no_visto.to_excel(os.path.join(dataset_dir, 'xlsx/llamados_v2_no_visto.xlsx'), index=False)\n",
    "llamados_v4_no_visto.to_excel(os.path.join(dataset_dir, 'xlsx/llamados_v4_no_visto.xlsx'), index=False)\n",
    "llamados_v5_no_visto.to_excel(os.path.join(dataset_dir, 'xlsx/llamados_v5_no_visto.xlsx'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "del llamados_v2, llamados_v4, llamados_v5\n",
    "del llamados_v4_no_visto, llamados_v5_no_visto, llamados_v2_no_visto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 separar train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. fecha hora a timestamp y escalado\n",
    "\n",
    "for dataset in todos_datasets:\n",
    "    dataset['timestamp_encoded'] = encoder.fit_transform(dataset[['llamado_fecha_hora']])\n",
    "    dataset['timestamp_scaled'] = scaler.fit_transform(dataset[['timestamp_encoded']])\n",
    "    dataset.drop('timestamp_encoded', axis=1, inplace=True)\n",
    "    dataset.drop('llamado_fecha_hora', axis=1, inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. escalar edades\n",
    "for dataset in todos_datasets:\n",
    "    dataset['victima_edad_escalada'] = scaler.fit_transform(dataset[['victima_edad']])\n",
    "    dataset['llamante_edad_escalada'] = scaler.fit_transform(dataset[['llamante_edad']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. pasar edad a categórica\n",
    "\n",
    "\n",
    "def categoria_edad (x):\n",
    "    if (x >= 0) and (x <= 11) :\n",
    "        return 'Niñez'\n",
    "    elif (x >= 12) and (x <=18):\n",
    "        return 'Adolescencia'\n",
    "    elif (x >= 19) and (x <=30):\n",
    "        return 'Juventud'\n",
    "    elif (x>=31) and (x<=65) :\n",
    "        return 'Vejez'\n",
    "    elif x>=66:\n",
    "        return 'Vejez mayor'\n",
    "    else:\n",
    "        return 'NS/NC'\n",
    "\n",
    "for dataset in todos_datasets:\n",
    "    dataset['victima_edad_cat'] = \\\n",
    "        dataset.victima_edad.apply(categoria_edad)\n",
    "    dataset['llamante_edad_cat'] = \\\n",
    "        dataset.llamante_edad.apply(categoria_edad)\n",
    "    dataset.drop(['victima_edad','llamante_edad'], axis=1, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. reemplazar NS/NC de convive por NA\n",
    "\n",
    "\n",
    "for dataset in todos_datasets:\n",
    "\n",
    "    # Replace the specified values with NaN\n",
    "    dataset.loc[:, 'victima_convive_agresor'] = dataset['victima_convive_agresor'].replace({' NS/NC': pd.NA})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 pasar edad_cat, momento_dia (V4, V5) y estacion_del_año (V4, V5) a dummy con un encoder ordinal\n",
    "\n",
    "\n",
    "for dataset in todos_datasets:\n",
    "    dataset['victima_edad_cat_dummy'] = label_encoder.fit_transform(dataset['victima_edad_cat'])\n",
    "    dataset['llamante_edad_cat_dummy'] = label_encoder.fit_transform(dataset['llamante_edad_cat'])\n",
    "    dataset.drop(['victima_edad_cat', 'llamante_edad_cat'], axis=1, inplace=True)\n",
    "\n",
    "for dataset in datasets_45:\n",
    "    dataset['momento_dummy'] = label_encoder.fit_transform(dataset['momento_dia'])\n",
    "    dataset['estacion_dummy'] = label_encoder.fit_transform(dataset['estacion_del_año'])\n",
    "    dataset.drop(['estacion_del_año','momento_dia',], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escalar las variables ordinales edad, momento del día y estación\n",
    "\n",
    "for dataset in todos_datasets:\n",
    "    dataset['victima_edad_dummy_scaled'] = scaler.fit_transform(dataset[['victima_edad_cat_dummy']])\n",
    "    dataset['llamante_edad_dummy_scaled'] = scaler.fit_transform(dataset[['llamante_edad_cat_dummy']])\n",
    "    dataset.drop('victima_edad_cat_dummy', axis=1, inplace=True)\n",
    "    dataset.drop('llamante_edad_cat_dummy', axis=1, inplace=True )\n",
    "\n",
    "for dataset in datasets_45:\n",
    "    dataset['momento_dummy_scaled'] = scaler.fit_transform(dataset[['momento_dummy']])\n",
    "    dataset['estacion_dummy_scaled'] = scaler.fit_transform(dataset[['estacion_dummy']])\n",
    "    dataset.drop('momento_dummy', axis=1, inplace=True)\n",
    "    dataset.drop('estacion_dummy', axis=1, inplace=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sacar todos los casos vacíos de convive, esos serán el dataset aparte final a predecir con el mejor modelo\n",
    "# encodear el resto del dataset, todo menos y_convive\n",
    "\n",
    "def one_hot_encoder(dataset):\n",
    "    columna_excluir = 'victima_convive_agresor'\n",
    "    columnas_cat = dataset.select_dtypes(include=['object']).columns.tolist()\n",
    "    columnas_cat.remove(columna_excluir)\n",
    "\n",
    "    # Apply one-hot encoding to object columns excluding the chosen one\n",
    "    df_encoded = pd.get_dummies(df, columns=object_columns)\n",
    "\n",
    "    # Display the DataFrame with one-hot encoded columns\n",
    "    print(df_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentos usando los datasets preparados para svm:\n",
    "\n",
    "- las variaciones son en las columnas de edad, en los datasets que tengo, y en los kernels de SVM\n",
    "\n",
    "##### Prueba 1, dataset V2, V3, V4\n",
    "- edad categórica pasada a dummy se va\n",
    "- edad numérica se queda pero solo los datos completos de ambas\n",
    "- corro SVN c =/= kernels\n",
    "\n",
    "##### Prueba 2, dataset V2, V3, V4\n",
    "- edad categórica pasada a dummy se va\n",
    "- edad numérica se queda pero solo los datos completos de victima\n",
    "- corro SVN c =/= kernels\n",
    "\n",
    "##### Prueba 3, dataset V2, V3, V4\n",
    "- edad categórica pasada a dummy se va\n",
    "- edad numérica se queda pero solo los datos completos de llamante\n",
    "- corro SVN c =/= kernels\n",
    "\n",
    "##### Prueba 4, dataset V2, V3, V4\n",
    "- edad numérica se va\n",
    "- edad categórica pasada a dummy se queda\n",
    "- corro SVN c =/= kernels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
