{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerías\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import gower\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import  GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.manifold import MDS\n",
    "import gc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directorios\n",
    "dataset_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(''))), 'datasets')\n",
    "image_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(''))), 'images')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset A: primer experimento con NMDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset a (edades categorizadas)\n",
    "\n",
    "dataset_a= pd.read_excel(os.path.join(dataset_dir, 'xlsx/llamados_v2.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorizar edad en dataset a\n",
    "\n",
    "\n",
    "def categoria_edad (x):\n",
    "    if (x >= 0) and (x <= 11) :\n",
    "        return 'Niñez'\n",
    "    elif (x >= 12) and (x <=18):\n",
    "        return 'Adolescencia'\n",
    "    elif (x >= 19) and (x <=30):\n",
    "        return 'Juventud'\n",
    "    elif (x>=31) and (x<=65) :\n",
    "        return 'Vejez'\n",
    "    elif x>=66:\n",
    "        return 'Vejez mayor'\n",
    "    else:\n",
    "        return 'NS/NC'\n",
    "\n",
    "\n",
    "dataset_a['victima_edad_cat'] = \\\n",
    "dataset_a.victima_edad.apply(categoria_edad)\n",
    "dataset_a['llamante_edad_cat'] = \\\n",
    "dataset_a.llamante_edad.apply(categoria_edad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columnas sin usar\n",
    "\n",
    "dataset_a.drop(['victima_edad', 'llamante_edad'], axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reemplazar nsnc por na\n",
    "dataset_a.loc[:, 'victima_convive_agresor'] = dataset_a['victima_convive_agresor'].replace({'NS/NC': pd.NA})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapear SI NO a 1 0\n",
    "dataset_a['victima_convive_agresor'] = dataset_a['victima_convive_agresor'].map({'SI': 1, 'NO':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_a.to_excel(\"/Users/vcolombo/Documents/tp especializacion/linea_137_llamados_vs/datasets/xlsx/llamados_dataset_a_nmds.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_a= pd.read_excel(os.path.join(dataset_dir, 'xlsx/llamados_dataset_a_nmds.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prop. SI: 14.39690748576503\n",
      "prop. NO: 64.40474324818472\n"
     ]
    }
   ],
   "source": [
    "# chequear proporciones previas\n",
    "print('prop. SI:', len(dataset_a[dataset_a['victima_convive_agresor']==1])/len(dataset_a)*100)\n",
    "print('prop. NO:',len(dataset_a[dataset_a['victima_convive_agresor']==0])/len(dataset_a)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separar features de target\n",
    "X = dataset_a.drop(['victima_convive_agresor'], axis=1)\n",
    "y_previo = dataset_a['victima_convive_agresor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar los índices de casos NSNC (vacíos)\n",
    "nsnc_indices = y_previo[y_previo.isna()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"NSNC\" rows from the target\n",
    "y = y_previo.drop(nsnc_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gower de X\n",
    "gower_X = gower.gower_matrix(X)\n",
    "print(\"gower para dataset_a hecho\")\n",
    "\n",
    "lista_dimensiones=[2,3,4,5,6,7]\n",
    "lista_modelos=[]\n",
    "contador_exp= 0\n",
    "for i in lista_dimensiones:\n",
    "    print('n_components: ', i)\n",
    "    # correr NMDS sobre el total del dataset\n",
    "    nmds = MDS(n_components=i ,metric=False, dissimilarity='precomputed', max_iter=300, random_state=0, normalized_stress=True) \n",
    "    X_nmds = nmds.fit_transform(gower_X)\n",
    "    print('Fit transform hecho')\n",
    "\n",
    "    # crear el test final con lo que corresponde a target de X transformado \n",
    "    test_final = X_nmds[nsnc_indices.tolist(), :]\n",
    "    print('Test final hecho')\n",
    "    test_final_df_a = pd.DataFrame(test_final, columns=[f'Component_{i}' for i in range(test_final.shape[1])])\n",
    "\n",
    "\n",
    "    print('Stress: ' + str(round(nmds.stress_,2)))\n",
    "    # quitar el test final \n",
    "    X_nmds_clean = pd.DataFrame(X_nmds).drop(nsnc_indices)\n",
    "\n",
    "\n",
    "    print('entrenando el modelo svm')\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=2)\n",
    "    for train_index, test_index in sss.split(X_nmds_clean, y):\n",
    "        X_train, X_test = X_nmds_clean.iloc[train_index], X_nmds_clean.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Parámetros de gridsearch\n",
    "    param_grid = {\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "\n",
    "\n",
    "    svm = SVC(class_weight='balanced')\n",
    "\n",
    "\n",
    "    # GridSearchCV\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='f1_weighted')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Mejor modelo\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Aplicar al test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "  # Evaluate the model\n",
    "    print(\"Best parameters found: \", grid_search.best_params_)\n",
    "    print(\"Best cross-validation f1: \", grid_search.best_score_)\n",
    "    print(\"Test set f1: \", f1_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"Classification report:\\n\", classification_report(y_test, y_pred, zero_division=1))\n",
    "    \n",
    "\n",
    "    # por cada modelo me guardo: n_components usado, best parameters, best cross validation acc, test set acc, classification report\n",
    "\n",
    "    contador_exp+=1\n",
    "\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lista_modelos_a.pkl', 'wb') as fp:\n",
    "    pickle.dump(lista_modelos, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_modelos_a = pd.read_pickle(\"lista_modelos_a.pkl\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_nmds, X_nmds_clean, dataset_a, X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elegir el mejor n_components y entrenar el modelo con los mejores params de gridsearch para aplicar a test final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_a.drop(['victima_convive_agresor'], axis=1)\n",
    "y_previo = dataset_a['victima_convive_agresor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsnc_indices = y_previo[y_previo.isna()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_previo.drop(nsnc_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test final hecho\n"
     ]
    }
   ],
   "source": [
    "# gower de X\n",
    "gower_X = gower.gower_matrix(X)\n",
    "\n",
    "# correr NMDS sobre el total del dataset\n",
    "nmds = MDS(n_components=7 ,metric=False, dissimilarity='precomputed', max_iter=300, random_state=0, normalized_stress=True) \n",
    "X_nmds = nmds.fit_transform(gower_X)\n",
    "\n",
    "# crear el test final con lo que corresponde a target de X transformado \n",
    "test_final = X_nmds[nsnc_indices.tolist(), :]\n",
    "print('Test final hecho')\n",
    "test_final_df_a = pd.DataFrame(test_final, columns=[f'Component_{i}' for i in range(test_final.shape[1])])\n",
    "\n",
    "# quitar el test final \n",
    "X_nmds_clean = pd.DataFrame(X_nmds).drop(nsnc_indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a svm Classifier\n",
    "svm_a = SVC(C=0.1, kernel='poly', degree=3, gamma='auto', class_weight='balanced',random_state=3)\n",
    "\n",
    "#Train the model using the training sets\n",
    "svm_a.fit(X_nmds_clean, y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "na_predictions_a = svm_a.predict(test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the predictions to the na_convive_df DataFrame\n",
    "test_final_df_a['victima_convive_agresor_pred'] = na_predictions_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "victima_convive_agresor_pred\n",
       "0.0    4058\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_final_df_a.victima_convive_agresor_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bets_svm_a.pkl', 'wb') as fp:\n",
    "    pickle.dump(svm_a, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset B: segundo experimento con NMDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llamados= pd.read_excel(os.path.join(dataset_dir, 'xlsx/llamados_v2.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llamados.drop(['llamante_edad'], axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_b = llamados[~llamados['victima_edad'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_b.loc[:, 'victima_convive_agresor'] = dataset_b['victima_convive_agresor'].replace({'NS/NC': pd.NA})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gm/4r6lhs5j5p12g3_ml4zjfy500000gq/T/ipykernel_58205/2095538111.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_b['victima_convive_agresor'] = dataset_b['victima_convive_agresor'].map({'SI': 1, 'NO': 0})\n"
     ]
    }
   ],
   "source": [
    "dataset_b['victima_convive_agresor'] = dataset_b['victima_convive_agresor'].map({'SI': 1, 'NO': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_b.to_excel(\"/Users/vcolombo/Documents/tp especializacion/linea_137_llamados_vs/datasets/xlsx/llamados_dataset_b_nmds.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_b= pd.read_excel(os.path.join(dataset_dir, 'xlsx/llamados_dataset_b_nmds.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separar features de target\n",
    "X = dataset_b.drop(['victima_convive_agresor'], axis=1)\n",
    "y_previo = dataset_b['victima_convive_agresor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar los índices de casos NSNC (vacíos)\n",
    "nsnc_indices = y_previo[y_previo.isna()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"NSNC\" rows from the target\n",
    "y = y_previo.drop(nsnc_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gower para dataset_a hecho\n",
      "n_components:  2\n",
      "Fit transform hecho\n",
      "Test final hecho\n",
      "Stress: 0.3\n",
      "entrenando el modelo svm\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      1.00      0.90      2334\n",
      "         1.0       1.00      0.00      0.00       524\n",
      "\n",
      "    accuracy                           0.82      2858\n",
      "   macro avg       0.91      0.50      0.45      2858\n",
      "weighted avg       0.85      0.82      0.73      2858\n",
      "\n",
      "n_components:  3\n",
      "Fit transform hecho\n",
      "Test final hecho\n",
      "Stress: 0.25\n",
      "entrenando el modelo svm\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      1.00      0.90      2334\n",
      "         1.0       1.00      0.00      0.00       524\n",
      "\n",
      "    accuracy                           0.82      2858\n",
      "   macro avg       0.91      0.50      0.45      2858\n",
      "weighted avg       0.85      0.82      0.73      2858\n",
      "\n",
      "n_components:  4\n",
      "Fit transform hecho\n",
      "Test final hecho\n",
      "Stress: 0.21\n",
      "entrenando el modelo svm\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      1.00      0.90      2334\n",
      "         1.0       1.00      0.00      0.00       524\n",
      "\n",
      "    accuracy                           0.82      2858\n",
      "   macro avg       0.91      0.50      0.45      2858\n",
      "weighted avg       0.85      0.82      0.73      2858\n",
      "\n",
      "n_components:  5\n",
      "Fit transform hecho\n",
      "Test final hecho\n",
      "Stress: 0.19\n",
      "entrenando el modelo svm\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      1.00      0.90      2334\n",
      "         1.0       1.00      0.00      0.00       524\n",
      "\n",
      "    accuracy                           0.82      2858\n",
      "   macro avg       0.91      0.50      0.45      2858\n",
      "weighted avg       0.85      0.82      0.73      2858\n",
      "\n",
      "n_components:  6\n",
      "Fit transform hecho\n",
      "Test final hecho\n",
      "Stress: 0.17\n",
      "entrenando el modelo svm\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      1.00      0.90      2334\n",
      "         1.0       1.00      0.00      0.00       524\n",
      "\n",
      "    accuracy                           0.82      2858\n",
      "   macro avg       0.91      0.50      0.45      2858\n",
      "weighted avg       0.85      0.82      0.73      2858\n",
      "\n",
      "n_components:  7\n",
      "Fit transform hecho\n",
      "Test final hecho\n",
      "Stress: 0.16\n",
      "entrenando el modelo svm\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      1.00      0.90      2334\n",
      "         1.0       1.00      0.00      0.00       524\n",
      "\n",
      "    accuracy                           0.82      2858\n",
      "   macro avg       0.91      0.50      0.45      2858\n",
      "weighted avg       0.85      0.82      0.73      2858\n",
      "\n",
      "n_components:  20\n",
      "Fit transform hecho\n",
      "Test final hecho\n",
      "Stress: 0.09\n",
      "entrenando el modelo svm\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      1.00      0.90      2334\n",
      "         1.0       1.00      0.00      0.00       524\n",
      "\n",
      "    accuracy                           0.82      2858\n",
      "   macro avg       0.91      0.50      0.45      2858\n",
      "weighted avg       0.85      0.82      0.73      2858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# gower de X\n",
    "gower_X = gower.gower_matrix(X)\n",
    "print(\"gower para dataset_a hecho\")\n",
    "\n",
    "lista_dimensiones=[2,3,4,5,6,7]\n",
    "lista_modelos=[]\n",
    "contador_exp= 0\n",
    "for i in lista_dimensiones:\n",
    "    print('n_components: ', i)\n",
    "    # correr NMDS sobre el total del dataset\n",
    "    nmds = MDS(n_components=i ,metric=False, dissimilarity='precomputed', max_iter=300, random_state=0, normalized_stress=True) \n",
    "    X_nmds = nmds.fit_transform(gower_X)\n",
    "    print('Fit transform hecho')\n",
    "\n",
    "    # crear el test final con lo que corresponde a target de X transformado \n",
    "    test_final = X_nmds[nsnc_indices.tolist(), :]\n",
    "    print('Test final hecho')\n",
    "    test_final_df_b = pd.DataFrame(test_final, columns=[f'Component_{i}' for i in range(test_final.shape[1])])\n",
    "\n",
    "\n",
    "    print('Stress: ' + str(round(nmds.stress_,2)))\n",
    "    # quitar el test final \n",
    "    X_nmds_clean = pd.DataFrame(X_nmds).drop(nsnc_indices)\n",
    "\n",
    "\n",
    "    print('entrenando el modelo svm')\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=2)\n",
    "    for train_index, test_index in sss.split(X_nmds_clean, y):\n",
    "        X_train, X_test = X_nmds_clean.iloc[train_index], X_nmds_clean.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Parámetros de gridsearch\n",
    "    param_grid = {\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "\n",
    "\n",
    "    svm = SVC(class_weight='balanced')\n",
    "\n",
    "\n",
    "    # GridSearchCV\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='f1_weighted')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Mejor modelo\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Aplicar al test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    " \n",
    "  # Evaluate the model\n",
    "    print(\"Best parameters found: \", grid_search.best_params_)\n",
    "    print(\"Best cross-validation f1: \", grid_search.best_score_)\n",
    "    print(\"Test set f1: \", f1_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"Classification report:\\n\", classification_report(y_test, y_pred, zero_division=1))\n",
    "\n",
    "    # por cada modelo me guardo: n_components usado, best parameters, best cross validation acc, test set acc, classification report\n",
    "\n",
    "    contador_exp+=1\n",
    "    \n",
    "\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lista_modelos_b.pkl', 'wb') as fp:\n",
    "    pickle.dump(lista_modelos, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elegir el mejor modelo, entrenar con esos parámetros, y testear sobre test final.\n",
    "\n",
    "del X_nmds, X_nmds_clean, dataset_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_b= pd.read_excel(os.path.join(dataset_dir, 'xlsx/llamados_dataset_b.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separar features de target\n",
    "X = dataset_b.drop(['victima_convive_agresor'], axis=1)\n",
    "y_previo = dataset_b['victima_convive_agresor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar los índices de casos NSNC (vacíos)\n",
    "nsnc_indices = y_previo[y_previo.isna()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sacar las filas del test final\n",
    "y = y_previo.drop(nsnc_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test final hecho\n"
     ]
    }
   ],
   "source": [
    "# gower de X\n",
    "gower_X = gower.gower_matrix(X)\n",
    "\n",
    "# correr NMDS sobre el total del dataset\n",
    "nmds = MDS(n_components=7 ,metric=False, dissimilarity='precomputed', max_iter=300, random_state=0, normalized_stress=True) \n",
    "X_nmds = nmds.fit_transform(gower_X)\n",
    "\n",
    "# crear el test final con lo que corresponde a target de X transformado \n",
    "test_final = X_nmds[nsnc_indices.tolist(), :]\n",
    "print('Test final hecho')\n",
    "test_final_df_b= pd.DataFrame(test_final, columns=[f'Component_{i}' for i in range(test_final.shape[1])])\n",
    "\n",
    "# quitar el test final \n",
    "X_nmds_clean = pd.DataFrame(X_nmds).drop(nsnc_indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejores parámetros: n_components=7\n",
    "SVM: 'kernel': 'poly', 'C': 0.1, and 'gamma': 'auto'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_nmds_clean, y, test_size=0.3,random_state=109) # 70% training and 30% test\n",
    "\n",
    "\n",
    "svm = SVC(C=0.1, kernel='poly', degree=3, gamma='auto', class_weight='balanced',random_state=3)\n",
    "\n",
    "\n",
    "#Create a svm Classifier\n",
    "svm_b = SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "svm_b.fit(X_nmds_clean, y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "na_predictions_b = svm_b.predict(test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the predictions to the na_convive_df DataFrame\n",
    "test_final_df_b['victima_convive_agresor_pred'] = na_predictions_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "victima_convive_agresor_pred\n",
       "0.0    2977\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_final_df_b.victima_convive_agresor_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bets_svm_b.pkl', 'wb') as fp:\n",
    "    pickle.dump(svm_b, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien hay diferencias en los valores de stress cuando varío los n_components, que mejoran a medida que los n_componenets suben, la variación de n_components no produce mejoras en la performance de los modelos de SVM, de hecho no parecería estar afectando el entrenamiento de ninguna manera ya que las métricas de accuracy y etc. de los mejores modelos dan los mismo variando los n_components."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
