{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset A: edades categorizadas (chequear toda la notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(''))), 'datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datos a usar\n",
    "Dataset de llamados completo, limpio con reducción de variables hecha a mano: variables agrupadas por temática, variables eliminadas por poco informativas, variables reducidas: hecho lugar, llamado provincia, llamante vinculo, victima nacionalidad, y agresor conocido/no conocido. \n",
    "\n",
    "\n",
    "##### Pipeline\n",
    "\n",
    "1. cargar dataset\n",
    "2. reemplazar NS/NC en convive por NA\n",
    "3. hacer modificaciones para svm. Considerar: Apply scikit's OneHotEncoder with the handle_unknown parameter set to \"ignore\"\n",
    "4. separar NA de convive, serán el dataset \"no visto\"\n",
    "5. separar features de target\n",
    "6. separar train-test \n",
    "7. armar modelo\n",
    "8. evaluar\n",
    "\n",
    "\n",
    "##### Modificaiones para SVM\n",
    "\n",
    "1. pasar datetime a timestamp y escalar --> OK\n",
    "2. escalar la variable edad --> OK\n",
    "3. pasar edad a categórica (en una columna distinta) --> OK\n",
    "4. Encodeo:\n",
    "   1. edad, momento del día y estación del año con un encoder ordinal\n",
    "   2. escalar las features encodeadas con ordinal\n",
    "   3. variables de SI/NO encodear para 1 y 0\n",
    "   4. el resto con one hot encoder\n",
    "5. borrar las categóricas para hacer más pequeño el dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. cargar dataset\n",
    "\n",
    "\n",
    "llamados= pd.read_excel(os.path.join(dataset_dir, 'xlsx/llamados_v3.xlsx'), parse_dates=['llamado_fecha_hora'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['llamado_fecha_hora', 'llamante_edad', 'llamante_genero',\n",
       "       'caso_judicializado', 'victima_a_resguardo', 'victima_edad',\n",
       "       'victima_genero', 'victima_discapacidad', 'victima_convive_agresor',\n",
       "       'vs_tocamiento_sexual', 'vs_intento_tocamiento', 'vs_grooming',\n",
       "       'vs_exhibicionismo', 'vs_obligacion_sacarse_fotos_pornograficas',\n",
       "       'vs_acoso_sexual', 'vs_iniciacion_sexual_forzada_inducida',\n",
       "       'vs_otra_forma_violencia_sexual', 'vs_no_sabe_no_contesta',\n",
       "       'ofv_sentimiento_amenaza', 'ofv_amenaza_explicita',\n",
       "       'ofv_violencia_fisica', 'ofv_enganio_seduccion', 'ofv_grooming',\n",
       "       'ofv_otra_forma_violencia', 'ofv_no_sabe_no_contesta', 'fin_de_semana',\n",
       "       'momento_dia', 'estacion_del_año', 'vs_explotacion_sexual_group',\n",
       "       'vs_violacion_group', 'vs_tentativa_group',\n",
       "       'agresor_conocido_no_conocido_red', 'vinculo_llamante_red',\n",
       "       'hecho_lugar_red', 'llamado_provincia_red', 'victima_nacionalidad_red'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llamados.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 reemplazar todos los NS/NC en convive por na\n",
    "\n",
    "llamados.loc[:, 'victima_convive_agresor'] = llamados['victima_convive_agresor'].replace({'NS/NC': pd.NA})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Modificaciones para SVM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.000000\n",
       "1        0.000060\n",
       "2        0.000121\n",
       "3        0.000181\n",
       "4        0.000181\n",
       "           ...   \n",
       "19138    0.999758\n",
       "19139    0.999940\n",
       "19140    0.999819\n",
       "19141    0.999879\n",
       "19142    0.999879\n",
       "Name: timestamp_encoded_scaled, Length: 19143, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. timestamp-fecha_hora encodeado y escalado\n",
    "scaler = MinMaxScaler()\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "\n",
    "llamados['timestamp_encoded'] = encoder.fit_transform(llamados[['llamado_fecha_hora']])\n",
    "llamados['timestamp_encoded_scaled'] = scaler.fit_transform(llamados[['timestamp_encoded']])\n",
    "    \n",
    "llamados.timestamp_encoded_scaled\n",
    "\n",
    "# sobra llamado_fecha_hora y timestamp_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. pasar edad a categórica\n",
    "\n",
    "def categoria_edad (x):\n",
    "    if (x >= 0) and (x <= 11) :\n",
    "        return 'Niñez'\n",
    "    elif (x >= 12) and (x <=18):\n",
    "        return 'Adolescencia'\n",
    "    elif (x >= 19) and (x <=30):\n",
    "        return 'Juventud'\n",
    "    elif (x>=31) and (x<=65) :\n",
    "        return 'Adultez'\n",
    "    elif x>=66:\n",
    "        return 'Vejez'\n",
    "    else:\n",
    "        return 'NS/NC'\n",
    "\n",
    "\n",
    "\n",
    "llamados['victima_edad_cat'] = \\\n",
    "llamados.victima_edad.apply(categoria_edad)\n",
    "llamados['llamante_edad_cat'] = \\\n",
    "llamados.llamante_edad.apply(categoria_edad)\n",
    "\n",
    "\n",
    "# sobra: victima_edad y llamante_edad  llamado_fecha_hora y timestamp_encoded  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llamados['victima_edad_cat_encoded'] = encoder.fit_transform(llamados[['victima_edad_cat']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "llamados['llamante_edad_cat_encoded'] = encoder.fit_transform(llamados[['llamante_edad_cat']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Variables categóricas que serán encodeadas con ordinal: edad cat (ordinal), momento día (ordinal), \n",
    "# estación del año (ordinal).\n",
    "# Además de encodearlas con ordinal, luego voy a escalar ese encoding ordinal. \n",
    "# FUENTE Encoding_Methods_for_Categorical_Data.pdf\n",
    "\n",
    "# 4.1 pasar edad_cat, momento_dia (V5) y estacion_del_año (V5) a dummy con un encoder ordinal\n",
    "\n",
    "llamados['momento_encoded'] = encoder.fit_transform(llamados[['momento_dia']])\n",
    "llamados['estacion_encoded'] = encoder.fit_transform(llamados[['estacion_del_año']])\n",
    "\n",
    "\n",
    "\n",
    "#sobra victima_edad_cat y llamante_edad_cat victima_edad y llamante_edad  llamado_fecha_hora y timestamp_encoded momento_dia y estacion_del_año "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4.2 escalar las variables ordinales edad, momento del día y estación\n",
    "\n",
    "\n",
    "llamados['victima_edad_encoded_scaled'] = scaler.fit_transform(llamados[['victima_edad_cat_encoded']])\n",
    "llamados['llamante_edad_encoded_scaled'] = scaler.fit_transform(llamados[['llamante_edad_cat_encoded']])\n",
    "llamados['momento_encoded_scaled'] = scaler.fit_transform(llamados[['momento_encoded']])\n",
    "llamados['estacion_encoded_scaled'] = scaler.fit_transform(llamados[['estacion_encoded']])\n",
    "\n",
    "\n",
    "#sobra victima_edad_cat_encoded y llamante_edad_cat_encoded, momento_encoded y estacion_encoded\n",
    "# momento_dia y estacion_del_año victima_edad_cat y llamante_edad_cat victima_edad y llamante_edad  llamado_fecha_hora y timestamp_encoded  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droppear las columnas que ya sé que no voy a usar\n",
    "llamados.drop(['victima_edad_cat_encoded', 'llamante_edad_cat_encoded', \n",
    "                 'momento_encoded', 'estacion_encoded', 'momento_dia',\n",
    "                 'estacion_del_año', 'victima_edad_cat', \n",
    "                 'llamante_edad_cat', 'victima_edad', 'llamante_edad',  \n",
    "                 'llamado_fecha_hora', 'timestamp_encoded'], axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "objetos = {}\n",
    "for column in llamados.columns:\n",
    "    if llamados[column].dtypes == object:\n",
    "        objetos[column] = llamados[column].unique()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llamante_genero': array(['Femenino', 'Masculino', 'NS/NC', 'Transgénero'], dtype=object),\n",
       " 'caso_judicializado': array(['NS/NC', 'NO', 'SI'], dtype=object),\n",
       " 'victima_a_resguardo': array(['SI', 'NO'], dtype=object),\n",
       " 'victima_genero': array(['Femenino', 'Masculino', 'NS/NC', 'Transgénero'], dtype=object),\n",
       " 'victima_discapacidad': array(['SI', 'NO', 'NS/NC'], dtype=object),\n",
       " 'victima_convive_agresor': array(['SI', 'NO', <NA>], dtype=object),\n",
       " 'vs_tocamiento_sexual': array(['SI', 'NO'], dtype=object),\n",
       " 'vs_intento_tocamiento': array(['NO', 'SI'], dtype=object),\n",
       " 'vs_grooming': array(['NO', 'SI'], dtype=object),\n",
       " 'vs_exhibicionismo': array(['NO', 'SI'], dtype=object),\n",
       " 'vs_obligacion_sacarse_fotos_pornograficas': array(['NO', 'SI'], dtype=object),\n",
       " 'vs_acoso_sexual': array(['NO', 'SI'], dtype=object),\n",
       " 'vs_iniciacion_sexual_forzada_inducida': array(['NO', 'SI'], dtype=object),\n",
       " 'vs_otra_forma_violencia_sexual': array(['NO', 'SI'], dtype=object),\n",
       " 'vs_no_sabe_no_contesta': array(['NO', 'SI'], dtype=object),\n",
       " 'ofv_sentimiento_amenaza': array(['SI', 'NO'], dtype=object),\n",
       " 'ofv_amenaza_explicita': array(['SI', 'NO'], dtype=object),\n",
       " 'ofv_violencia_fisica': array(['NO', 'SI'], dtype=object),\n",
       " 'ofv_enganio_seduccion': array(['NO', 'SI'], dtype=object),\n",
       " 'ofv_grooming': array(['NO', 'SI'], dtype=object),\n",
       " 'ofv_otra_forma_violencia': array(['NO', 'SI'], dtype=object),\n",
       " 'ofv_no_sabe_no_contesta': array(['NO', 'SI'], dtype=object),\n",
       " 'vs_explotacion_sexual_group': array(['NO', 'SI'], dtype=object),\n",
       " 'vs_violacion_group': array(['SI', 'NO'], dtype=object),\n",
       " 'vs_tentativa_group': array(['NO', 'SI'], dtype=object),\n",
       " 'agresor_conocido_no_conocido_red': array(['Agresor conocido (familiar))',\n",
       "        'Conocido no familiar (Amigo, vecino, entre otros)', 'NS/NC',\n",
       "        'Desconocido'], dtype=object),\n",
       " 'vinculo_llamante_red': array(['Institución', 'Conocido (fam/no fam)', 'Víctima', 'Agresor/a',\n",
       "        'NS/NC'], dtype=object),\n",
       " 'hecho_lugar_red': array(['Vivienda de la Víctima', 'Otro', 'Espacio público', 'NS/NC',\n",
       "        'Vivienda del Agresor', 'Redes Sociales'], dtype=object),\n",
       " 'llamado_provincia_red': array(['Región Norte', 'CABA', 'Región Central', 'Buenos Aires', 'NS/NC',\n",
       "        'Región Patagónica'], dtype=object),\n",
       " 'victima_nacionalidad_red': array(['Argentina', 'NS/NC', 'Otra'], dtype=object)}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Variables de SI/NO encodear con dummy\n",
    "# Find columns that only contain 'SI' and 'NO'\n",
    "\n",
    "si_no_columns = []\n",
    "cat_mas_de_dos = []\n",
    "for column in llamados.columns:\n",
    "    if llamados[column].dtypes == object:\n",
    "        if set(llamados[column].unique()).issubset({'SI', 'NO'}):\n",
    "            si_no_columns.append(column)\n",
    "        else:\n",
    "            cat_mas_de_dos.append(column)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['victima_a_resguardo',\n",
       " 'vs_tocamiento_sexual',\n",
       " 'vs_intento_tocamiento',\n",
       " 'vs_grooming',\n",
       " 'vs_exhibicionismo',\n",
       " 'vs_obligacion_sacarse_fotos_pornograficas',\n",
       " 'vs_acoso_sexual',\n",
       " 'vs_iniciacion_sexual_forzada_inducida',\n",
       " 'vs_otra_forma_violencia_sexual',\n",
       " 'vs_no_sabe_no_contesta',\n",
       " 'ofv_sentimiento_amenaza',\n",
       " 'ofv_amenaza_explicita',\n",
       " 'ofv_violencia_fisica',\n",
       " 'ofv_enganio_seduccion',\n",
       " 'ofv_grooming',\n",
       " 'ofv_otra_forma_violencia',\n",
       " 'ofv_no_sabe_no_contesta',\n",
       " 'vs_explotacion_sexual_group',\n",
       " 'vs_violacion_group',\n",
       " 'vs_tentativa_group']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si_no_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodear_one_hot = ['llamante_genero',\n",
    " 'caso_judicializado',\n",
    " 'victima_genero',\n",
    " 'victima_discapacidad',\n",
    " 'agresor_conocido_no_conocido_red',\n",
    " 'vinculo_llamante_red',\n",
    " 'hecho_lugar_red',\n",
    " 'llamado_provincia_red',\n",
    " 'victima_nacionalidad_red']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encodear si/no \n",
    "\n",
    "for col in si_no_columns:\n",
    "    llamados[col] = llamados[col].map({'SI': 1, 'NO':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encodear target\n",
    "llamados['victima_convive_agresor'] = llamados['victima_convive_agresor'].map({'SI': 1, 'NO':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encodear con one hot \n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=True) # considerar drop first is sparse false\n",
    "\n",
    "# Fit and transform the data\n",
    "encoded_sparse = encoder.fit_transform(llamados[encodear_one_hot])\n",
    "\n",
    "# Convert the sparse matrix to a dense array\n",
    "encoded_array = encoded_sparse.toarray()\n",
    "\n",
    "# Create a DataFrame with the encoded columns\n",
    "encoded_df = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out(encodear_one_hot))\n",
    "\n",
    "# Drop the original columns that were one-hot encoded\n",
    "llamados.drop(columns=encodear_one_hot, inplace=True)\n",
    "\n",
    "# Concatenate the original DataFrame with the encoded DataFrame\n",
    "llamados = pd.concat([llamados, encoded_df], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sacar todos los casos vacíos de convive y ponerlos en un nuevo dataset aparte, \n",
    "# será el test final a predecir con el mejor modelo\n",
    "\n",
    "# Create a DataFrame with rows where 'convive' is NA\n",
    "test_final = llamados[llamados['victima_convive_agresor'].isna()]\n",
    "\n",
    "# Remove rows where 'convive' is NA from the original DataFrame\n",
    "llamados = llamados.dropna(subset=['victima_convive_agresor'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llamados.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "llamados.drop(['victima_edad_escalada', 'llamante_edad_escalada'], axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'C': 1, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Best cross-validation f1:  0.8702039958656039\n",
      "Test set f1:  0.8708323889876585\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.95      0.93      2466\n",
      "         1.0       0.72      0.54      0.62       551\n",
      "\n",
      "    accuracy                           0.88      3017\n",
      "   macro avg       0.81      0.75      0.77      3017\n",
      "weighted avg       0.87      0.88      0.87      3017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target variable\n",
    "X = llamados.drop(columns=['victima_convive_agresor'])\n",
    "y = llamados['victima_convive_agresor']\n",
    "\n",
    "# Stratified split\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC()\n",
    "\n",
    "# Perform GridSearchCV to find the best parameters\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='f1_weighted')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation f1: \", grid_search.best_score_)\n",
    "print(\"Test set f1: \", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the best model to the subset of the original dataset\n",
    "X_na = test_final.drop(columns=['victima_convive_agresor', 'llamante_edad_escalada', 'victima_edad_escalada'])\n",
    "na_predictions = best_model.predict(X_na)\n",
    "\n",
    "# Add the predictions to the na_convive_df DataFrame\n",
    "test_final['victima_convive_agresor_pred'] = na_predictions\n",
    "\n",
    "print(\"\\nPredictions for NA 'convive' values:\")\n",
    "print(test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "victima_convive_agresor_pred\n",
       "0.0    3748\n",
       "1.0     310\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_final.victima_convive_agresor_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4058, 78)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15085, 75)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llamados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "victima_convive_agresor\n",
       "0.0    12329\n",
       "1.0     2756\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llamados.victima_convive_agresor.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proporción de SI en dataset original 0.18269804441498178 Proporción de SI en test final 0.0763923114834894\n",
      "Proporción de NO en dataset original 0.8173019555850183 Proporción de NO en test final 0.9236076885165106\n"
     ]
    }
   ],
   "source": [
    "print('Proporción de SI en dataset original', llamados.victima_convive_agresor.value_counts()[1]/llamados.shape[0], 'Proporción de SI en test final',test_final.victima_convive_agresor_pred.value_counts()[1]/test_final.shape[0] )\n",
    "print('Proporción de NO en dataset original', test_final.victima_convive_agresor_pred.value_counts()[1]/test_final.shape[0], 'Proporción de NO en test final', test_final.victima_convive_agresor_pred.value_counts()[0]/test_final.shape[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
